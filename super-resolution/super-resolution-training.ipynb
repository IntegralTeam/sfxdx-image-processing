{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sys import stderr\n",
    "\n",
    "import numpy as np\n",
    "import six\n",
    "from keras.callbacks import Callback\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "class TQDMCallback(Callback):\n",
    "    def __init__(self, outer_description=\"Training\",\n",
    "                 inner_description_initial=\"Epoch: {epoch}\",\n",
    "                 inner_description_update=\"Epoch: {epoch} - {metrics}\",\n",
    "                 metric_format=\"{name}: {value:0.3f}\",\n",
    "                 separator=\", \",\n",
    "                 leave_inner=True,\n",
    "                 leave_outer=True,\n",
    "                 show_inner=True,\n",
    "                 show_outer=True,\n",
    "                 output_file=stderr,\n",
    "                 initial=0):\n",
    "\n",
    "        self.outer_description = outer_description\n",
    "        self.inner_description_initial = inner_description_initial\n",
    "        self.inner_description_update = inner_description_update\n",
    "        self.metric_format = metric_format\n",
    "        self.separator = separator\n",
    "        self.leave_inner = leave_inner\n",
    "        self.leave_outer = leave_outer\n",
    "        self.show_inner = show_inner\n",
    "        self.show_outer = show_outer\n",
    "        self.output_file = output_file\n",
    "        self.tqdm_outer = None\n",
    "        self.tqdm_inner = None\n",
    "        self.epoch = None\n",
    "        self.running_logs = None\n",
    "        self.inner_count = None\n",
    "        self.initial = initial\n",
    "\n",
    "    def tqdm(self, desc, total, leave, initial=0):\n",
    "        return tqdm(desc=desc, total=total, leave=leave, file=self.output_file, initial=initial)\n",
    "\n",
    "    def build_tqdm_outer(self, desc, total):\n",
    "        return self.tqdm(desc=desc, total=total, leave=self.leave_outer, initial=self.initial)\n",
    "\n",
    "    def build_tqdm_inner(self, desc, total):\n",
    "        return self.tqdm(desc=desc, total=total, leave=self.leave_inner)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch = epoch\n",
    "        desc = self.inner_description_initial.format(epoch=self.epoch)\n",
    "        self.mode = 0  # samples\n",
    "        if 'samples' in self.params:\n",
    "            self.inner_total = self.params['samples']\n",
    "        elif 'nb_sample' in self.params:\n",
    "            self.inner_total = self.params['nb_sample']\n",
    "        else:\n",
    "            self.mode = 1  # steps\n",
    "            self.inner_total = self.params['steps']\n",
    "        if self.show_inner:\n",
    "            self.tqdm_inner = self.build_tqdm_inner(desc=desc, total=self.inner_total)\n",
    "        self.inner_count = 0\n",
    "        self.running_logs = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        metrics = self.format_metrics(logs)\n",
    "        desc = self.inner_description_update.format(epoch=epoch, metrics=metrics)\n",
    "        if self.show_inner:\n",
    "            self.tqdm_inner.desc = desc\n",
    "            # set miniters and mininterval to 0 so last update displays\n",
    "            self.tqdm_inner.miniters = 0\n",
    "            self.tqdm_inner.mininterval = 0\n",
    "            self.tqdm_inner.update(self.inner_total - self.tqdm_inner.n)\n",
    "            self.tqdm_inner.close()\n",
    "        if self.show_outer:\n",
    "            self.tqdm_outer.update(1)        \n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if self.mode == 0:\n",
    "            update = logs['size']\n",
    "        else:\n",
    "            update = 1\n",
    "        self.inner_count += update\n",
    "        if self.inner_count < self.inner_total:\n",
    "            self.append_logs(logs)\n",
    "            metrics = self.format_metrics(self.running_logs)\n",
    "            desc = self.inner_description_update.format(epoch=self.epoch, metrics=metrics)\n",
    "            if self.show_inner:\n",
    "                self.tqdm_inner.desc = desc\n",
    "                self.tqdm_inner.update(update)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if self.show_outer:\n",
    "            epochs = (self.params['epochs'] if 'epochs' in self.params\n",
    "                      else self.params['nb_epoch'])\n",
    "            self.tqdm_outer = self.build_tqdm_outer(desc=self.outer_description,\n",
    "                                                    total=epochs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        if self.show_outer:\n",
    "            self.tqdm_outer.close()\n",
    "\n",
    "    def append_logs(self, logs):\n",
    "        metrics = self.params['metrics']\n",
    "        for metric, value in six.iteritems(logs):\n",
    "            if metric in metrics:\n",
    "                if metric in self.running_logs:\n",
    "                    self.running_logs[metric].append(value[()])\n",
    "                else:\n",
    "                    self.running_logs[metric] = [value[()]]\n",
    "\n",
    "    def format_metrics(self, logs):\n",
    "        metrics = self.params['metrics']\n",
    "        strings = [self.metric_format.format(name=metric, value=np.mean(logs[metric], axis=None)) for metric in metrics\n",
    "                   if\n",
    "                   metric in logs]\n",
    "        return self.separator.join(strings)\n",
    "    \n",
    "    \n",
    "\n",
    "class TQDMNotebookCallback(TQDMCallback):\n",
    "    def __init__(self,\n",
    "                 outer_description=\"Training\",\n",
    "                 inner_description_initial=\"Epoch {epoch}\",\n",
    "                 inner_description_update=\"[{metrics}] \",\n",
    "                 metric_format=\"{name}: {value:0.3f}\",\n",
    "                 separator=\", \",\n",
    "                 leave_inner=False,\n",
    "                 leave_outer=True,\n",
    "                 output_file=sys.stderr,\n",
    "                 initial=0, **kwargs):\n",
    "        super(TQDMNotebookCallback, self).__init__(outer_description=outer_description,\n",
    "                                                   inner_description_initial=inner_description_initial,\n",
    "                                                   inner_description_update=inner_description_update,\n",
    "                                                   metric_format=metric_format,\n",
    "                                                   separator=separator,\n",
    "                                                   leave_inner=leave_inner,\n",
    "                                                   leave_outer=leave_outer,\n",
    "                                                   output_file=output_file,\n",
    "                                                   initial=initial, **kwargs)\n",
    "\n",
    "    def tqdm(self, desc, total, leave, initial=0):\n",
    "        return tqdm_notebook(desc=desc, total=total, leave=leave, initial=initial)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import callbacks\n",
    "# from keras.layers import Conv2D, BatchNormalization, Input, Activation, UpSampling2D, Lambda, Deconv2D\n",
    "from keras.layers import Conv2D, BatchNormalization, Input, Activation, UpSampling2D, Lambda\n",
    "from keras.layers.convolutional import Deconv2D\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "# from tqdm import TQDMNotebookCallback\n",
    "from vgg16_avg import VGG16_Avg\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10390601803155334164, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6668420649\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10101611027989538602\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU check\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to install a Javascript widget for this to work\n",
    "params = {'verbose': 0, 'callbacks': [TQDMNotebookCallback(leave_inner=True)]}\n",
    "lr_img_dir = 'data/lr_images/'\n",
    "hr_img_dir = 'data/hr_images/'\n",
    "fnames = os.listdir('data/mirflickr/')\n",
    "lr_dims = (72, 72, 3) # Number of channels is last dim with tf backend\n",
    "hr_dims = (288, 288, 3)\n",
    "\n",
    "# lr_dims = (128, 128, 3)\n",
    "# hr_dims = (400, 400, 3) # 4X times better resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN architechture used will be similar to ResNets.\n",
    "- Has convolutional blocks.\n",
    "- Has residual connections and hence need residual blocks.\n",
    "- Upsampling would be done using de-convolution blocks.\n",
    "(Instead of deconvolution block, we could use UpSampling2D from keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Conv2D(filters, kernel_size=(size, size), strides=stride, padding=mode)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, (1,1))\n",
    "    x = conv_block(x, nf, 3, (1,1), act=False)\n",
    "    return add([x, ip]) # Adding the transformed feature map with the original input (residual connection)\n",
    "\n",
    "def deconv_block(x, filters, size, stride=(2,2)):\n",
    "    x = Deconv2D(filters, kernel_size=(size, size), strides=stride, \n",
    "        padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(filters, kernel_size=(size, size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "inp = Input(shape=lr_dims)\n",
    "x = conv_block(inp, 64, 9, (1,1))\n",
    "for i in range(4): \n",
    "    x = res_block(x)\n",
    "x = up_block(x, 64, 3) # Try up-sampling vs. deconv instead (deconv might produce checkerboard patterns)\n",
    "x = up_block(x, 64, 3)\n",
    "x = Conv2D(3, kernel_size=(9, 9), activation='tanh', padding='same')(x)\n",
    "outp = Lambda(lambda x: (x+1)*127.5)(x) # +1 since tanh gives values between -1 and 1, and we need to scale to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, our model takes a Low resolution 100x100 image, which is transformed through a series of conv blocks and residual connections. Then we start to up-sample/deconv the feature map to make it of size 400x400. \n",
    "\n",
    "Finally, we compare the 'content loss' between the generated image and the ground truth High resolution 400x400 image, when both are passed through some convolutional layer in Vgg16. In doing so, we are able to train a network that can upsample an image and recreate the higher resolution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 72, 72, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 72, 72, 64)   15616       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 72, 72, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 72, 72, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 72, 72, 64)   36928       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 72, 72, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 72, 72, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 72, 72, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 72, 72, 64)   256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 72, 72, 64)   0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 72, 72, 64)   36928       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 72, 72, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 72, 72, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 72, 72, 64)   36928       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 72, 72, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 72, 72, 64)   0           batch_normalization_38[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 72, 72, 64)   36928       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 72, 72, 64)   256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 72, 72, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 72, 72, 64)   36928       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 72, 72, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 72, 72, 64)   0           batch_normalization_40[0][0]     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 72, 72, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 72, 72, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 72, 72, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 72, 72, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 72, 72, 64)   256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 72, 72, 64)   0           batch_normalization_42[0][0]     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 144, 144, 64) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 144, 144, 64) 36928       up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 144, 144, 64) 256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 144, 144, 64) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 288, 288, 64) 0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 288, 288, 64) 36928       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 288, 288, 64) 256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 288, 288, 64) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 288, 288, 3)  15555       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 288, 288, 3)  0           conv2d_48[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "Total params: 403,267\n",
      "Trainable params: 401,859\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = Model(inputs=inp, outputs=outp)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing and de-preprocessing as done in the style transfer tutorial\n",
    "rn_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "\n",
    "preproc = lambda x: (x - rn_mean)[:, :, :, ::-1]\n",
    "deproc = lambda x,s: np.clip(x.reshape(s)[:, :, :, ::-1] + rn_mean, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 72, 72, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open('data/lr_images/im002.jpg')\n",
    "img_arr = preproc(np.expand_dims(im, axis=0))\n",
    "shp = img_arr.shape\n",
    "shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 288, 288, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_23 (Lambda)           (None, 288, 288, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 288, 288, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 288, 288, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling2 (None, 144, 144, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 144, 144, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 144, 144, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling2 (None, 72, 72, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 72, 72, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 72, 72, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 72, 72, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling2 (None, 36, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 36, 36, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 36, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 36, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (AveragePooling2 (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling2 (None, 9, 9, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_inp = Input(shape=hr_dims)\n",
    "vgg = VGG16_Avg(include_top=False, input_tensor=Lambda(preproc)(vgg_inp))\n",
    "\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to learn the \"upsampling network\" (base_model), and are just using VGG to calculate the loss function, we set the VGG layers to not be trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in vgg.layers: \n",
    "    l.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to return a model's output at a specified layer number (basically for VGG)\n",
    "def get_outp(model, ln): \n",
    "    return model.get_layer(f'block{ln}_conv1').output\n",
    "\n",
    "vgg_content = Model(vgg_inp, [get_outp(vgg, o) for o in [1,2,3]]) # Layers 1,2,3\n",
    "\n",
    "# Two VGG networks\n",
    "# 1. One that takes the original ground truth HRes image as input\n",
    "# 2. Second that takes the generated HRes image as input\n",
    "vgg1 = vgg_content(Lambda(preproc)(vgg_inp))\n",
    "vgg2 = vgg_content(Lambda(preproc)(outp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the MSE, and the ouput has shape (1, batch_size)\n",
    "def mean_sqr_b(diff): \n",
    "    dims = list(range(1,K.ndim(diff)))\n",
    "    return K.expand_dims(K.sqrt(K.mean(diff**2, axis=dims)), axis=0)\n",
    "\n",
    "# Test the above with numpy code\n",
    "t = np.ones(shape=(8,200,200,3))\n",
    "dims = list(range(1, np.ndim(t)))\n",
    "K.eval(K.expand_dims(K.sqrt(K.mean(K.variable(t)**2, axis=dims)), axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=[0.1, 0.8, 0.1] # Considering conv blocks 1,2,3 - different weights for each\n",
    "def content_loss_fn(x): # x is an array of VGG1 outputs appended with an array of VGG2 outputs\n",
    "    res = 0; n=len(w)\n",
    "    for i in range(n): # Iterate through the 3 conv blocks\n",
    "        # Below, we compare x[0] and x[3] | x[1] and x[4] and so on\n",
    "        # x[0], x[1], x[2] are outputs of vgg1\n",
    "        # x[3], x[4], x[5] are outputs of vgg2\n",
    "        res += mean_sqr_b(x[i]-x[i+n]) * w[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a zero vector as a target parameter, which is a **necessary parameter when calling fit on a keras model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 72, 72, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 72, 72, 64)   15616       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 72, 72, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 72, 72, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 72, 72, 64)   36928       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 72, 72, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 72, 72, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 72, 72, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 72, 72, 64)   256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 72, 72, 64)   0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 72, 72, 64)   36928       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 72, 72, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 72, 72, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 72, 72, 64)   36928       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 72, 72, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 72, 72, 64)   0           batch_normalization_38[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 72, 72, 64)   36928       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 72, 72, 64)   256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 72, 72, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 72, 72, 64)   36928       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 72, 72, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 72, 72, 64)   0           batch_normalization_40[0][0]     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 72, 72, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 72, 72, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 72, 72, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 72, 72, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 72, 72, 64)   256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 72, 72, 64)   0           batch_normalization_42[0][0]     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 144, 144, 64) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 144, 144, 64) 36928       up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 144, 144, 64) 256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 144, 144, 64) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 288, 288, 64) 0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 288, 288, 64) 36928       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 288, 288, 64) 256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 288, 288, 64) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 288, 288, 3)  15555       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 288, 288, 3)  0                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 288, 288, 3)  0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 288, 288, 3)  0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 288, 288, 3)  0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_11 (Model)                [(None, 288, 288, 64 555328      lambda_24[0][0]                  \n",
      "                                                                 lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (1, None)            0           model_11[1][0]                   \n",
      "                                                                 model_11[1][1]                   \n",
      "                                                                 model_11[1][2]                   \n",
      "                                                                 model_11[2][0]                   \n",
      "                                                                 model_11[2][1]                   \n",
      "                                                                 model_11[2][2]                   \n",
      "==================================================================================================\n",
      "Total params: 958,595\n",
      "Trainable params: 401,859\n",
      "Non-trainable params: 556,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sr = Model([inp, vgg_inp], Lambda(content_loss_fn)(vgg1+vgg2))# array of VGG1 outputs appended with an array of VGG2 outputs\n",
    "targ = np.zeros(shape=list( hr_dims ) + [1]) # From FastAI notebook\n",
    "# targ = np.zeros(shape=(BATCH_SIZE,)) # This is used in my batch_generator function\n",
    "# Target and input 1st dimensions should match\n",
    "\n",
    "model_sr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Generator and load data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100006\n"
     ]
    }
   ],
   "source": [
    "def load_batch(file_list):\n",
    "    lr_img_array = []\n",
    "    hr_img_array = []\n",
    "    \n",
    "    for file_ in file_list:\n",
    "        lr_im = Image.open(lr_img_dir + file_)\n",
    "        lr_img_array.append(np.array(lr_im))\n",
    "        \n",
    "        hr_im = Image.open(hr_img_dir + file_)\n",
    "        hr_img_array.append(np.array(hr_im))\n",
    "        \n",
    "    return lr_img_array, hr_img_array\n",
    "\n",
    "def batch_generator(files, BATCH_SIZE):\n",
    "    L = len(files)\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = BATCH_SIZE\n",
    "\n",
    "        while batch_start < L:\n",
    "            \n",
    "            limit = min(batch_end, L)\n",
    "            file_list = files[batch_start: limit]\n",
    "            lr_img_array, hr_img_array = load_batch(file_list)\n",
    "            targ = np.zeros(shape=(BATCH_SIZE,))\n",
    "            \n",
    "            yield [np.array(lr_img_array), np.array(hr_img_array)], targ # a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += BATCH_SIZE   \n",
    "            batch_end += BATCH_SIZE\n",
    "\n",
    "\n",
    "fnames = [f for f in fnames if f.endswith('jpg')]\n",
    "print(len(fnames))\n",
    "\n",
    "train_files, _temp = train_test_split(fnames, test_size = 400)\n",
    "dev_files, test_files = train_test_split(_temp, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "N_EPOCHS = 2\n",
    "STEPS_PER_EPOCH = len(train_files)//BATCH_SIZE\n",
    "VAL_STEPS = len(dev_files)//BATCH_SIZE\n",
    "\n",
    "# The final layer returns losses as shape (1, batch_size) \n",
    "# - the loss is set to 'mae' to take mean average error across the batch\n",
    "model_sr.compile(optimizer='adam', loss='mse') \n",
    "# model_sr.fit(x=[arr_lr, arr_hr], y=targ, batch_size=8, epochs=3)\n",
    "\n",
    "history = model_sr.fit_generator(\n",
    "    generator = batch_generator(train_files, BATCH_SIZE),\n",
    "    epochs = N_EPOCHS,\n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    validation_data = batch_generator(dev_files, BATCH_SIZE), \n",
    "    validation_steps = VAL_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights('saved_models/sr_upsampling_epoch_2_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
